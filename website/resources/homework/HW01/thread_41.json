{
  "id": 6919682,
  "user_id": 967449,
  "course_id": 84647,
  "original_id": null,
  "editor_id": 606786,
  "accepted_id": null,
  "duplicate_id": null,
  "number": 41,
  "type": "post",
  "title": "HW1 Q2",
  "content": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/v8FvhyhlTA9eaUQjejgvloFW\" width=\"568\" height=\"1300\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/JXGh6ySdvu0hHgg9su143s9x\" width=\"510\" height=\"838\"/></figure><paragraph>Problem context:</paragraph><paragraph>This is a problem that asks you to carefully work through why SGD works for a simple setting. It's not clear that everyone in the class has seen a proof of SGD working in any setting, and it is important to understand this stuff for at least a simple example. (Just watching lecture is not enough.) The demo part is interesting to see so you can viscerally appreciate what is going on with SGD. There is a lot to observe and soak in from the demo actually, so we really want to encourage you to play with it.</paragraph><paragraph>This particular proof is elementary and gets at essential ideas, but it is not commonly appreciated or known. The core ideas here can be generalized broadly beyond this particular setting, but the mathematical abstractions involved (PL conditions, etc...) don't have the required \"conceptual bang for the buck\" needed to make it into this foundational course</paragraph></document>",
  "document": "Problem context:\n\nThis is a problem that asks you to carefully work through why SGD works for a simple setting. It's not clear that everyone in the class has seen a proof of SGD working in any setting, and it is important to understand this stuff for at least a simple example. (Just watching lecture is not enough.) The demo part is interesting to see so you can viscerally appreciate what is going on with SGD. There is a lot to observe and soak in from the demo actually, so we really want to encourage you to play with it.\n\nThis particular proof is elementary and gets at essential ideas, but it is not commonly appreciated or known. The core ideas here can be generalized broadly beyond this particular setting, but the mathematical abstractions involved (PL conditions, etc...) don't have the required \"conceptual bang for the buck\" needed to make it into this foundational course",
  "category": "Problem Sets",
  "subcategory": "",
  "subsubcategory": "",
  "flag_count": 0,
  "star_count": 0,
  "view_count": 565,
  "unique_view_count": 176,
  "vote_count": 0,
  "reply_count": 7,
  "unresolved_count": 2,
  "is_locked": false,
  "is_pinned": false,
  "is_private": false,
  "is_endorsed": false,
  "is_answered": false,
  "is_student_answered": false,
  "is_staff_answered": false,
  "is_archived": false,
  "is_anonymous": false,
  "is_megathread": true,
  "anonymous_comments": false,
  "approved_status": "approved",
  "created_at": "2025-09-06T10:55:29.916796+10:00",
  "updated_at": "2025-12-18T09:55:02.73221+11:00",
  "deleted_at": null,
  "pinned_at": null,
  "anonymous_id": 0,
  "vote": 0,
  "is_seen": false,
  "is_starred": false,
  "is_watched": null,
  "glanced_at": null,
  "new_reply_count": 0,
  "duplicate_title": null,
  "answers": [],
  "comments": [
    {
      "id": 16137193,
      "user_id": 1308098,
      "course_id": 84647,
      "thread_id": 6919682,
      "original_id": null,
      "parent_id": null,
      "editor_id": null,
      "number": 1,
      "type": "comment",
      "kind": "normal",
      "content": "<document version=\"2.0\"><paragraph>In question (b), do we need a transpose for V?<break/>i.e. w′′ = V^T w′ ?</paragraph></document>",
      "document": "In question (b), do we need a transpose for V?\ni.e. w′′ = V^T w′ ?",
      "flag_count": 0,
      "vote_count": 0,
      "is_endorsed": false,
      "is_anonymous": false,
      "is_private": false,
      "is_resolved": true,
      "created_by_bot_id": null,
      "created_at": "2025-09-09T03:16:27.865535+10:00",
      "updated_at": null,
      "deleted_at": null,
      "anonymous_id": 0,
      "vote": 0,
      "comments": [
        {
          "id": 16142826,
          "user_id": 606786,
          "course_id": 84647,
          "thread_id": 6919682,
          "original_id": null,
          "parent_id": 16137193,
          "editor_id": null,
          "number": 2,
          "type": "comment",
          "kind": "normal",
          "content": "<document version=\"2.0\"><paragraph>It's a matrix. You get to define it as you need to. </paragraph></document>",
          "document": "It's a matrix. You get to define it as you need to. ",
          "flag_count": 0,
          "vote_count": 2,
          "is_endorsed": false,
          "is_anonymous": false,
          "is_private": false,
          "is_resolved": false,
          "created_by_bot_id": null,
          "created_at": "2025-09-09T09:58:33.975233+10:00",
          "updated_at": "2025-09-12T03:51:24.207507+10:00",
          "deleted_at": null,
          "anonymous_id": 0,
          "vote": 0,
          "comments": []
        }
      ]
    },
    {
      "id": 16189564,
      "user_id": 833750,
      "course_id": 84647,
      "thread_id": 6919682,
      "original_id": null,
      "parent_id": null,
      "editor_id": null,
      "number": 3,
      "type": "comment",
      "kind": "normal",
      "content": "<document version=\"2.0\"><paragraph>This may be a stupid question, but in (k), I think I'm missing the connection between the augmented perspective of ridge regression and the exponential convergence. I know that in the previous parts we proved that with SGD the expectation of loss is exponentially going down to zero, but why is this applied only in the augmented matrix perspective and not in the original ridge? Is this because the regularization parameter would directly influence $\\tilde{X}$?</paragraph><paragraph/></document>",
      "document": "This may be a stupid question, but in (k), I think I'm missing the connection between the augmented perspective of ridge regression and the exponential convergence. I know that in the previous parts we proved that with SGD the expectation of loss is exponentially going down to zero, but why is this applied only in the augmented matrix perspective and not in the original ridge? Is this because the regularization parameter would directly influence $\\tilde{X}$?\n\n",
      "flag_count": 0,
      "vote_count": 0,
      "is_endorsed": false,
      "is_anonymous": false,
      "is_private": false,
      "is_resolved": true,
      "created_by_bot_id": null,
      "created_at": "2025-09-13T05:32:39.449048+10:00",
      "updated_at": null,
      "deleted_at": null,
      "anonymous_id": 0,
      "vote": 0,
      "comments": [
        {
          "id": 16193867,
          "user_id": 1294638,
          "course_id": 84647,
          "thread_id": 6919682,
          "original_id": null,
          "parent_id": 16189564,
          "editor_id": null,
          "number": 4,
          "type": "comment",
          "kind": "normal",
          "content": "<document version=\"2.0\"><paragraph>I second this. I am failing to grok the point that is being made in the text and in the notebook for this problem. I understand what the math states in terms of convergence, and that we can make some statements about the constants C1, C2 which determine this exponential convergence and bound eta, but what specifically is the takeaway from this problem supposed to be? A longer explanation would be very helpful.</paragraph><paragraph/></document>",
          "document": "I second this. I am failing to grok the point that is being made in the text and in the notebook for this problem. I understand what the math states in terms of convergence, and that we can make some statements about the constants C1, C2 which determine this exponential convergence and bound eta, but what specifically is the takeaway from this problem supposed to be? A longer explanation would be very helpful.\n\n",
          "flag_count": 0,
          "vote_count": 0,
          "is_endorsed": false,
          "is_anonymous": false,
          "is_private": false,
          "is_resolved": false,
          "created_by_bot_id": null,
          "created_at": "2025-09-13T14:32:42.605593+10:00",
          "updated_at": null,
          "deleted_at": null,
          "anonymous_id": 0,
          "vote": 0,
          "comments": [
            {
              "id": 16193932,
              "user_id": 606786,
              "course_id": 84647,
              "thread_id": 6919682,
              "original_id": null,
              "parent_id": 16193867,
              "editor_id": null,
              "number": 5,
              "type": "comment",
              "kind": "normal",
              "content": "<document version=\"2.0\"><paragraph>The important thing here is that different perspectives on the same problem can behave qualitatively differently when you try to solve them. The augmented feature approach to ridge satisfies the \"can get to zero loss\" condition while the standard approach or just using weight decay does not. And so they behave differently under SGD with a constant learning rate.</paragraph><paragraph>Why is this important? Because many deep networks behave like they're \"augmented features\" in the real world because there are way more parameters than there are training points. </paragraph></document>",
              "document": "The important thing here is that different perspectives on the same problem can behave qualitatively differently when you try to solve them. The augmented feature approach to ridge satisfies the \"can get to zero loss\" condition while the standard approach or just using weight decay does not. And so they behave differently under SGD with a constant learning rate.\n\nWhy is this important? Because many deep networks behave like they're \"augmented features\" in the real world because there are way more parameters than there are training points. ",
              "flag_count": 0,
              "vote_count": 0,
              "is_endorsed": false,
              "is_anonymous": false,
              "is_private": false,
              "is_resolved": false,
              "created_by_bot_id": null,
              "created_at": "2025-09-13T14:48:33.372207+10:00",
              "updated_at": null,
              "deleted_at": null,
              "anonymous_id": 0,
              "vote": 0,
              "comments": []
            }
          ]
        }
      ]
    },
    {
      "id": 16241128,
      "user_id": 970785,
      "course_id": 84647,
      "thread_id": 6919682,
      "original_id": null,
      "parent_id": null,
      "editor_id": null,
      "number": 6,
      "type": "comment",
      "kind": "normal",
      "content": "<document version=\"2.0\"><paragraph>Here is the solution for part d of question 2, I am very confused about how the identiy relating x_i and x_i hat is derived. Would you please clarify it a little bit?</paragraph><figure><image src=\"https://static.us.edusercontent.com/files/jMdeaoaULcJivb3qRE3hXC0j\" width=\"655\" height=\"179.43784639746636\"/></figure><figure><image src=\"https://static.us.edusercontent.com/files/b1Cxm3OpWuuXNRyUg4h0tbeV\" width=\"122\" height=\"59\"/></figure></document>",
      "document": "Here is the solution for part d of question 2, I am very confused about how the identiy relating x_i and x_i hat is derived. Would you please clarify it a little bit?",
      "flag_count": 0,
      "vote_count": 0,
      "is_endorsed": false,
      "is_anonymous": false,
      "is_private": false,
      "is_resolved": false,
      "created_by_bot_id": null,
      "created_at": "2025-09-17T14:45:46.751705+10:00",
      "updated_at": null,
      "deleted_at": null,
      "anonymous_id": 0,
      "vote": 0,
      "comments": []
    },
    {
      "id": 16290854,
      "user_id": 1759011,
      "course_id": 84647,
      "thread_id": 6919682,
      "original_id": null,
      "parent_id": null,
      "editor_id": null,
      "number": 7,
      "type": "comment",
      "kind": "normal",
      "content": "<document version=\"2.0\"><paragraph>Hi there! Correct me if I'm wrong, I think in the solution page 8 and 9, the correct formula of parameter c_1 and c_2 under the formula (66) and (73) should be:</paragraph><math>c_1=\\frac{4}{n}\\sigma_{\\min}^2</math><math>c_2=\\frac{4}{n}\\sigma_{\\max}^2\\rho_{ }^2</math><paragraph>In short, the</paragraph><math>\\eta\\ \\eta_{ }^2</math><paragraph>should be taken off from the formula of c_1 and c_2 in the solution respectively. Thank you for your attention! </paragraph></document>",
      "document": "Hi there! Correct me if I'm wrong, I think in the solution page 8 and 9, the correct formula of parameter c_1 and c_2 under the formula (66) and (73) should be:\n\n$$c_1=\\frac{4}{n}\\sigma_{\\min}^2$$\n\n$$c_2=\\frac{4}{n}\\sigma_{\\max}^2\\rho_{ }^2$$\n\nIn short, the\n\n$$\\eta\\ \\eta_{ }^2$$\n\nshould be taken off from the formula of c_1 and c_2 in the solution respectively. Thank you for your attention! ",
      "flag_count": 0,
      "vote_count": 0,
      "is_endorsed": false,
      "is_anonymous": false,
      "is_private": false,
      "is_resolved": false,
      "created_by_bot_id": null,
      "created_at": "2025-09-22T09:17:33.85993+10:00",
      "updated_at": "2025-09-22T14:34:26.945908+10:00",
      "deleted_at": null,
      "anonymous_id": 0,
      "vote": 0,
      "comments": []
    }
  ]
}