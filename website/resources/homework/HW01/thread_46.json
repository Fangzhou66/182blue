{
  "id": 6919704,
  "user_id": 967449,
  "course_id": 84647,
  "original_id": null,
  "editor_id": 606786,
  "accepted_id": null,
  "duplicate_id": null,
  "number": 46,
  "type": "post",
  "title": "HW1 Q7",
  "content": "<document version=\"2.0\"><figure><image src=\"https://static.us.edusercontent.com/files/lRPdaXgzmA1KcQNDE6o2VBCz\" width=\"658\" height=\"700.310421286031\"/></figure><paragraph>Problem context: </paragraph><paragraph>This can be viewed as a continuation of the problem on the last HW, where here, we are also providing you with an opportunity to review basic conditional expectations in the context of jointly normal vectors. This interpretation provides you with an intuitive anchor for the Kernel Ridge form. Although we do not ask here, it also gives you a way to get an estimate for uncertainty in the solution to ridge regression by looking at the entire posterior. (This problem should also help you review more probability.)</paragraph><paragraph>This question will also be helpful for the large number of you who might find yourself in need of using Gaussian-Process based Bayesian approaches for machine learning. These tend to be quite useful in a diverse set of application domains where uncertainty quantification is useful, and is a place where Deep Learning approaches are increasingly being folded in (to help metalearn good kernels for application domains).</paragraph></document>",
  "document": "Problem context: \n\nThis can be viewed as a continuation of the problem on the last HW, where here, we are also providing you with an opportunity to review basic conditional expectations in the context of jointly normal vectors. This interpretation provides you with an intuitive anchor for the Kernel Ridge form. Although we do not ask here, it also gives you a way to get an estimate for uncertainty in the solution to ridge regression by looking at the entire posterior. (This problem should also help you review more probability.)\n\nThis question will also be helpful for the large number of you who might find yourself in need of using Gaussian-Process based Bayesian approaches for machine learning. These tend to be quite useful in a diverse set of application domains where uncertainty quantification is useful, and is a place where Deep Learning approaches are increasingly being folded in (to help metalearn good kernels for application domains).",
  "category": "Problem Sets",
  "subcategory": "",
  "subsubcategory": "",
  "flag_count": 0,
  "star_count": 0,
  "view_count": 465,
  "unique_view_count": 213,
  "vote_count": 0,
  "reply_count": 0,
  "unresolved_count": 0,
  "is_locked": false,
  "is_pinned": false,
  "is_private": false,
  "is_endorsed": false,
  "is_answered": false,
  "is_student_answered": false,
  "is_staff_answered": false,
  "is_archived": false,
  "is_anonymous": false,
  "is_megathread": true,
  "anonymous_comments": false,
  "approved_status": "approved",
  "created_at": "2025-09-06T11:00:02.670544+10:00",
  "updated_at": "2025-12-17T17:48:05.690956+11:00",
  "deleted_at": null,
  "pinned_at": null,
  "anonymous_id": 0,
  "vote": 0,
  "is_seen": false,
  "is_starred": false,
  "is_watched": null,
  "glanced_at": null,
  "new_reply_count": 0,
  "duplicate_title": null,
  "answers": [],
  "comments": []
}